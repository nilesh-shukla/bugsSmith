{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "650ad9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import threading\n",
    "import time\n",
    "import nest_asyncio\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ec1123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODLE_FILE_PATH = './random_forest_model.pkl'\n",
    "EXPECTED_FEATURES = [\n",
    "    'default_profile_image',\n",
    "    'statuses_count',\n",
    "    'followers_count',\n",
    "    'friends_count',\n",
    "    'protected',\n",
    "    'name_length',\n",
    "    'follower_ratio'\n",
    "]\n",
    "\n",
    "RAW_COLUMNS_NEEDED = {\n",
    "    'statuses_count': 'statuses_count',\n",
    "    'followers_count': 'followers_count',\n",
    "    'friends_count': 'friends_count',\n",
    "    'default_profile_image': 'default_profile_image',\n",
    "    'protected': 'protected',\n",
    "    'name': 'name'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add28715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ./random_forest_model.pkl loaded succesfully.\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    MODEL = joblib.load(MODLE_FILE_PATH)\n",
    "    print(f\"Model {MODLE_FILE_PATH} loaded succesfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Missing model file: {MODLE_FILE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c69ec5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<flask_cors.extension.CORS at 0x1d104828d70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22f1d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_risk_category(score):\n",
    "    if score >= 91:\n",
    "        return {\"category\": \"CRITICAL RISK\", \"color\": \"red\"}\n",
    "    if score >= 66:\n",
    "        return {\"category\": \"BOT\", \"color\": \"amber\"}\n",
    "    if score >= 31:\n",
    "        return {\"category\": \"MODERATE\", \"color\": \"yellow\"}\n",
    "    return {\"category\": \"GENUINE\", \"color\": \"green\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6c886b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when re-running cells in a notebook, remove existing view functions to avoid duplicate registration errors\n",
    "for _ep in ('health','batch_predict'):\n",
    "    if _ep in app.view_functions:\n",
    "        app.view_functions.pop(_ep)\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health():\n",
    "    return jsonify({'status': 'ok'}), 200\n",
    "\n",
    "@app.route('/batch-predict', methods=['POST'])\n",
    "def batch_predict():\n",
    "    # basic validations\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file part in the request'}), 400\n",
    "\n",
    "    file = request.files['file']\n",
    "    if file.filename == '' or not file.filename.endswith('.csv'):\n",
    "        return jsonify({'error': 'No selected file or file is not a CSV'}), 400\n",
    "    \n",
    "    raw = file.read()\n",
    "    try:\n",
    "        file_content = raw.decode(\"utf-8\")\n",
    "    except Exception as e:\n",
    "        file_content = raw.decode(\"latin1\", errors=\"replace\")\n",
    "\n",
    "    df = pd.read_csv(StringIO(file_content))\n",
    "\n",
    "    try:\n",
    "        # normalization and type coercion\n",
    "        # lowercase the incoming column names to avoid case-mismatch with model features\n",
    "        df.columns = [c.lower() for c in df.columns]\n",
    "        df['followers_count'] = pd.to_numeric(df.get('followers_count', 0), errors='coerce').fillna(0)\n",
    "        df['friends_count'] = pd.to_numeric(df.get('friends_count', 0), errors='coerce').fillna(0)\n",
    "        df['statuses_count'] = pd.to_numeric(df.get('statuses_count', 0), errors='coerce').fillna(0)\n",
    "        df['default_profile_image'] = pd.to_numeric(df.get('default_profile_image', 0), errors='coerce').fillna(0)\n",
    "        df['protected'] = pd.to_numeric(df.get('protected', 0), errors='coerce').fillna(0)\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': 'Data Pre-cleaning Failed', 'details': str(e)}), 400\n",
    "\n",
    "    # ensure columns exist and track completeness\n",
    "    feature_present_count = 0\n",
    "    missing_features_list = []\n",
    "    for expected_raw_col, default_col_name in RAW_COLUMNS_NEEDED.items():\n",
    "        if default_col_name in df.columns:\n",
    "            df[default_col_name] = df[default_col_name].fillna(0)\n",
    "            feature_present_count = feature_present_count + 1\n",
    "        else:\n",
    "            df[default_col_name] = 0\n",
    "            missing_features_list.append(default_col_name)\n",
    "\n",
    "    try:\n",
    "        df['name_raw'] = df.get('name', pd.Series(['unknown']*len(df))).fillna('unknown')\n",
    "        df['name_length'] = df['name_raw'].apply(lambda x: len(str(x)))\n",
    "        df['follower_ratio'] = df['followers_count'] / (df['friends_count'] + 1)\n",
    "        df['default_profile_image'] = df['default_profile_image'].astype(int)\n",
    "        df['protected'] = df['protected'].astype(int)\n",
    "        df['statuses_count'] = df['statuses_count'].astype(int)\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': 'Data Transformation Failed', 'details': str(e)}), 500\n",
    "\n",
    "    # prediction and downstream processing wrapped to return JSON on error\n",
    "    try:\n",
    "        X_predict = df[EXPECTED_FEATURES]\n",
    "        prediction_probas = MODEL.predict_proba(X_predict)[:, 1]\n",
    "        df['Suspicion_Score'] = np.round(prediction_probas * 100, 2)\n",
    "        df['Risk_Analysis'] = df['Suspicion_Score'].apply(assign_risk_category)\n",
    "        df['Risk_Category'] = df['Risk_Analysis'].apply(lambda x: x['category'])\n",
    "        df['Risk_Color'] = df['Risk_Analysis'].apply(lambda x: x['color'])\n",
    "    except Exception as e:\n",
    "\n",
    "        return jsonify({'error': 'Prediction Failed', 'details': str(e)}), 500\n",
    "\n",
    "    completness_message = f\"{feature_present_count} of {len(RAW_COLUMNS_NEEDED)} critical raw columns present. Missing : {', '.join(missing_features_list) if missing_features_list else 'None' }\"\n",
    "    df_suspicious = df[df['Suspicion_Score'] > 30].sort_values(by = 'Suspicion_Score', ascending=False)\n",
    "    avg_suspicion = df_suspicious['Suspicion_Score'].mean() if not df_suspicious.empty else 0\n",
    "    final_table_data = df_suspicious[[\n",
    "        'id', 'name_raw',  'screen_name', 'Suspicion_Score', 'Risk_Category', 'Risk_Color'\n",
    "    ]].rename(columns={'id': 'Profile_ID', 'name_raw': 'Name', 'screen_name': 'Handle'})\n",
    "\n",
    "    globals()['LAST_VIZ_DF'] = df.copy()\n",
    "\n",
    "    response_data = {\n",
    "        'completness_score': feature_present_count,\n",
    "        'completness_total': len(RAW_COLUMNS_NEEDED),\n",
    "        'completness_message': completness_message,\n",
    "        'profiles': final_table_data.to_dict('records'),\n",
    "        'suspicion_score_average': round(avg_suspicion, 0)\n",
    "    }\n",
    "    return jsonify(response_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa201b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/viz-data', methods=['GET'])\n",
    "def viz_data():\n",
    "    global LAST_VIZ_DF\n",
    "    if 'LAST_VIZ_DF' not in globals() or LAST_VIZ_DF is None:\n",
    "        return jsonify({'error': 'No visualization data available yet.'}), 404\n",
    "\n",
    "    df = LAST_VIZ_DF.copy()\n",
    "\n",
    "    # split genuine / fake using the same threshold used in batch_predict (>30 suspicious => flagged)\n",
    "    genuine = df[df['Suspicion_Score'] <= 30] if 'Suspicion_Score' in df.columns else df.iloc[0:0]\n",
    "    fake = df[df['Suspicion_Score'] > 30] if 'Suspicion_Score' in df.columns else df.iloc[0:0]\n",
    "\n",
    "    # Followers vs Following scatter (limit to N points to keep payload reasonable)\n",
    "    N_SAMPLE = 1000\n",
    "    def ff_records(d):\n",
    "        cols = []\n",
    "        if 'followers_count' in d.columns and 'friends_count' in d.columns:\n",
    "            recs = d[['followers_count','friends_count']].dropna().head(N_SAMPLE)\n",
    "            cols = recs.to_dict(orient='records')\n",
    "        return cols\n",
    "    genuineData = ff_records(genuine)\n",
    "    fakeData = ff_records(fake)\n",
    "\n",
    "    # Profile picture distribution (default_profile_image assumed 0 => custom picture, non-zero => default)\n",
    "    def pic_counts(d):\n",
    "        if 'default_profile_image' in d.columns:\n",
    "            has = int((d['default_profile_image'] == 0).sum())\n",
    "            no = int((d['default_profile_image'] != 0).sum())\n",
    "        else:\n",
    "            has, no = 0, len(d)\n",
    "        return has, no\n",
    "    g_has, g_no = pic_counts(genuine)\n",
    "    f_has, f_no = pic_counts(fake)\n",
    "    profilePicData = [\n",
    "        {'label': 'Has Picture', 'Genuine': g_has, 'Fake': f_has},\n",
    "        {'label': 'No Picture', 'Genuine': g_no, 'Fake': f_no},\n",
    "    ]\n",
    "\n",
    "    # Privacy (protected vs public)\n",
    "    def privacy_counts(d):\n",
    "        if 'protected' in d.columns:\n",
    "            protected = int(d['protected'].sum())\n",
    "            public = int(len(d) - protected)\n",
    "        else:\n",
    "            protected, public = 0, len(d)\n",
    "        return [{'name': 'Protected', 'value': protected}, {'name': 'Public', 'value': public}]\n",
    "    genuinePrivacy = privacy_counts(genuine)\n",
    "    fakePrivacy = privacy_counts(fake)\n",
    "\n",
    "    # Feature importance (if model exposes it)\n",
    "    featureImportance = []\n",
    "    try:\n",
    "        import numpy as _np\n",
    "        if 'MODEL' in globals() and hasattr(MODEL, 'feature_importances_'):\n",
    "            fi = _np.asarray(MODEL.feature_importances_).tolist()\n",
    "            for f_name, importance in zip(EXPECTED_FEATURES, fi):\n",
    "                featureImportance.append({'feature': f_name, 'importance': float(importance)})\n",
    "    except Exception:\n",
    "        featureImportance = []\n",
    "\n",
    "    response = {\n",
    "        'genuineData': genuineData,\n",
    "        'fakeData': fakeData,\n",
    "        'profilePicData': profilePicData,\n",
    "        'genuinePrivacy': genuinePrivacy,\n",
    "        'fakePrivacy': fakePrivacy,\n",
    "        'featureImportance': featureImportance,\n",
    "    }\n",
    "    return jsonify(response), 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c879d91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flask] run_flask_app starting on port 8000\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:8000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flask] server_thread started: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Dec/2025 23:50:04] \"GET /health HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2025 23:50:05] \"POST /batch-predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Dec/2025 11:51:04] \"GET /viz-data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Dec/2025 11:51:04] \"GET /viz-data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Dec/2025 11:51:10] \"GET /viz-data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Dec/2025 11:51:10] \"GET /viz-data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Dec/2025 11:51:24] \"GET /viz-data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Dec/2025 11:51:24] \"GET /viz-data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Dec/2025 11:51:32] \"GET /viz-data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Dec/2025 11:51:32] \"GET /viz-data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Dec/2025 11:57:11] \"GET /health HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Dec/2025 11:57:11] \"POST /batch-predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Dec/2025 11:57:13] \"GET /viz-data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Dec/2025 11:57:13] \"GET /viz-data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Dec/2025 11:59:27] \"GET /health HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Dec/2025 11:59:27] \"POST /batch-predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Dec/2025 11:59:46] \"GET /viz-data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Dec/2025 11:59:46] \"GET /viz-data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Dec/2025 12:02:44] \"GET /viz-data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Dec/2025 12:02:44] \"GET /viz-data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Dec/2025 12:51:30] \"GET /viz-data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Dec/2025 12:51:30] \"GET /viz-data HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Start Flask server in background with robust logging and provide a small readiness endpoint\n",
    "# added by coppilot for robustness\n",
    "import traceback\n",
    "nest_asyncio.apply()\n",
    "st = globals().get('server_thread', None)\n",
    "\n",
    "def _is_thread_alive(t):\n",
    "    try:\n",
    "        return bool(t and getattr(t, 'is_alive', lambda: False)())\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "if not _is_thread_alive(st):\n",
    "    def run_flask_app():\n",
    "        global server_thread\n",
    "        try:\n",
    "            print(\"[flask] run_flask_app starting on port 8000\")\n",
    "            app.run(debug=False, use_reloader=False, port=8000)\n",
    "        except Exception as e:\n",
    "            print(\"[flask] run_flask_app exception:\", e)\n",
    "            traceback.print_exc()\n",
    "\n",
    "    server_thread = threading.Thread(target=run_flask_app, daemon=True)\n",
    "    server_thread.start()\n",
    "    time.sleep(0.2)\n",
    "    print(\"[flask] server_thread started:\", _is_thread_alive(server_thread))\n",
    "else:\n",
    "    print(\"[flask] server_thread already running:\", _is_thread_alive(st))\n",
    "\n",
    "@app.route('/viz-ready', methods=['GET'])\n",
    "def viz_ready():\n",
    "    st = globals().get('server_thread', None)\n",
    "    alive = bool(st and getattr(st, 'is_alive', lambda: False)())\n",
    "    has_df = 'LAST_VIZ_DF' in globals() and globals().get('LAST_VIZ_DF') is not None\n",
    "    return jsonify({'server_thread_alive': alive, 'has_last_viz_df': bool(has_df)}), 200"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
